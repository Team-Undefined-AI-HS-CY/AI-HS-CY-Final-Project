{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from settings import *\n",
    "\n",
    "from utils.models.yolo import load_model as load_yolo_model\n",
    "from utils.general import clean_session\n",
    "from utils.models.ocr import predict\n",
    "from utils.images import show_image, dilate_image, label_components, filter_components, get_bounding_boxes, prepare_img_for_prediction, visualize_bounding_boxes, get_components_mask, plot_images\n",
    "\n",
    "from utils.models.ocr import load_model as load_ocr_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_yolo_model()\n",
    "ocr_model1 = load_ocr_model(version=1)\n",
    "ocr_model2 = load_ocr_model(version=2)\n",
    "ocr_model2_5 = load_ocr_model(version=2.5)\n",
    "ocr_model3 = load_ocr_model(version=3)\n",
    "\n",
    "ALL_OCR_MODELS = [ocr_model1, ocr_model2, ocr_model2_5, ocr_model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_IMAGES = f\"{YOLO_DATASETS_DIR}/License-Plate-Dataset/test/images\"\n",
    "TEST_IMAGES = f\"test_images/test_image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO\n",
    "\n",
    "results = yolo_model(TEST_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    #result.show()  # display to screen\n",
    "    # result.save(filename=f'{result_path}/Test_Images_Results/result{i}.jpg')  # save to disk\n",
    "    # print(result.boxes.data.tolist())\n",
    "    # print(result.orig_img)\n",
    "\n",
    "    image = cv2.imread(result.path, cv2.IMREAD_GRAYSCALE)\n",
    "    show_image(image, \"Original Image\")\n",
    "    for box in result.boxes:\n",
    "        print(f\"Box: {box.cpu().data.numpy()}\")\n",
    "        x1, y1, x2, y2 = map(int, box.cpu().data.numpy()[0][:4])\n",
    "        print(f\"Coordinates: {x1, y1, x2, y2}\")\n",
    "        cropped_img = image[y1:y2, x1:x2]\n",
    "        show_image(cropped_img, \"Cropped image\")\n",
    "\n",
    "\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        original_area = image.shape[0] * image.shape[1]\n",
    "        original_area_ratio = area / original_area\n",
    "        print(f\"Original area ratio: {original_area_ratio}\")\n",
    "        K = 1\n",
    "        padding_number = int(K / original_area_ratio)\n",
    "        print(f\"Padding: {padding_number}\")\n",
    "\n",
    "        padded_image = cv2.copyMakeBorder(cropped_img, padding_number, padding_number, padding_number, padding_number, cv2.BORDER_CONSTANT, value=0)\n",
    "        show_image(padded_image, \"Padded image\")\n",
    "        padded_area = padded_image.shape[0] * padded_image.shape[1]\n",
    "        padded_area_ratio = area / padded_area\n",
    "\n",
    "        processed_image = dilate_image(padded_image)\n",
    "        show_image(processed_image, \"Processed image\")\n",
    "\n",
    "        labels = label_components(processed_image)\n",
    "\n",
    "        # lower and upper bound must also be proportional to the padding_number\n",
    "        # Set lower bound and upper bound criteria for characters\n",
    "        lower = (padded_area // 90) * padded_area_ratio # TODO: TUNE\n",
    "        upper = (padded_area // 10) * padded_area_ratio # TODO: TUNE\n",
    "\n",
    "        components = filter_components(labels, lower, upper)\n",
    "\n",
    "        mask = get_components_mask(padded_image, components)\n",
    "\n",
    "        bounding_boxes = get_bounding_boxes(mask)\n",
    "        print(f\"Detected {len(bounding_boxes)} characters\")\n",
    "\n",
    "        predictions = \"\"\n",
    "        for i, box in enumerate(bounding_boxes):\n",
    "            x, y, w, h = box\n",
    "            K2 = 1.25\n",
    "            extra_h = int(K2 * h)\n",
    "            extra_w = int(K2 * w)\n",
    "\n",
    "            roi = mask[y:y+h, x:x+w]\n",
    "            show_image(roi, f\"ROI {i}\")\n",
    "            char = prepare_img_for_prediction(roi)\n",
    "            show_image(char, f\"Character {i}\")\n",
    "            prediction = [predict(ocr_model, char) for ocr_model in ALL_OCR_MODELS]\n",
    "            print(f\"Prediction for character {i}: {prediction}\")\n",
    "            predictions += prediction\n",
    "\n",
    "        results_images = []\n",
    "\n",
    "        for model_num in range(len(ALL_OCR_MODELS)):\n",
    "            result_image = visualize_bounding_boxes(padded_image, bounding_boxes, predictions)\n",
    "            results_images.append(result_image)\n",
    "            show_image(result_image, f\"Model {model_num} detections\")\n",
    "            license_plate = \"\".join([res[0] for res in predictions[model_num]])\n",
    "            print(f\"License plate: {license_plate}\")\n",
    "    # print an image with all the models side by side\n",
    "    plot_images(results_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup resources and free\n",
    "clean_session()\n",
    "print(\"Freed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
